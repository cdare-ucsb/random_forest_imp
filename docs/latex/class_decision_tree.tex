\doxysection{Decision\+Tree Class Reference}
\hypertarget{class_decision_tree}{}\label{class_decision_tree}\index{DecisionTree@{DecisionTree}}


A class that represents a decision tree model using the ID3 algorithm for classification.  




{\ttfamily \#include $<$Decision\+Tree.\+h$>$}

Inheritance diagram for Decision\+Tree\+:\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[height=2.000000cm]{class_decision_tree}
\end{center}
\end{figure}
\doxysubsubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{class_decision_tree_a1ba47e4a3519b4eb63bb6e23e792b32d}{Decision\+Tree}} (int max\+\_\+depth, int min\+\_\+samples\+\_\+split)
\begin{DoxyCompactList}\small\item\em Constructor for the \doxylink{class_decision_tree}{Decision\+Tree} class. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_decision_tree_a02eeb6db8794933b278d5e1399551058}{\texorpdfstring{$\sim$}{\string~}\+Decision\+Tree}} ()
\begin{DoxyCompactList}\small\item\em Destructor for the \doxylink{class_decision_tree}{Decision\+Tree} class. \end{DoxyCompactList}\item 
double \mbox{\hyperlink{class_decision_tree_a012ddf141c98805dee234feda82bfbb7}{predict}} (const std\+::vector$<$ double $>$ \&sample) const override
\begin{DoxyCompactList}\small\item\em Predict method. \end{DoxyCompactList}\item 
int \mbox{\hyperlink{class_decision_tree_a5f555b5ecf4a639abae198d996e49a5a}{get\+\_\+num\+\_\+nodes}} ()
\begin{DoxyCompactList}\small\item\em Get the number of nodes in the decision tree. \end{DoxyCompactList}\item 
int \mbox{\hyperlink{class_decision_tree_a375a37a13ace5f6e303f7e180f73f0e8}{get\+\_\+height}} ()
\begin{DoxyCompactList}\small\item\em Get the height of the decision tree. \end{DoxyCompactList}\item 
void \mbox{\hyperlink{class_decision_tree_ad2548d5cda462085844cb8d977f9f8cd}{fit}} (std\+::shared\+\_\+ptr$<$ \mbox{\hyperlink{class_data_frame}{Data\+Frame}} $>$ df, const std\+::string \&label\+\_\+column) override
\begin{DoxyCompactList}\small\item\em The fit method trains the decision tree using the ID3 algorithm. \end{DoxyCompactList}\item 
string \mbox{\hyperlink{class_decision_tree_a87a02c9842a2e727248535d86bcfb29e}{print}} (vector$<$ string $>$ col\+\_\+names)
\begin{DoxyCompactList}\small\item\em Print method for the decision tree. \end{DoxyCompactList}\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
A class that represents a decision tree model using the ID3 algorithm for classification. 

This class represents a decision tree model that can be used for classification tasks. The tree is built using the ID3 algorithm, which is a top-\/down, greedy algorithm that selects the best attribute to split the data at each node based on the information gain. The tree is represented as a collection of nodes, where each node contains a decision rule based on an attribute and a value, and a pointer to its child nodes. The tree can be trained using the fit method, which takes a \doxylink{class_data_frame}{Data\+Frame} object containing the training data and a label column, and builds the tree using the ID3 algorithm. The tree can be printed using the print method, which returns a string representation of the tree. The tree can be used to make predictions using the predict method, which takes a sample vector of feature values and returns the predicted class label. 

\doxysubsection{Constructor \& Destructor Documentation}
\Hypertarget{class_decision_tree_a1ba47e4a3519b4eb63bb6e23e792b32d}\index{DecisionTree@{DecisionTree}!DecisionTree@{DecisionTree}}
\index{DecisionTree@{DecisionTree}!DecisionTree@{DecisionTree}}
\doxysubsubsection{\texorpdfstring{DecisionTree()}{DecisionTree()}}
{\footnotesize\ttfamily \label{class_decision_tree_a1ba47e4a3519b4eb63bb6e23e792b32d} 
Decision\+Tree\+::\+Decision\+Tree (\begin{DoxyParamCaption}\item[{int}]{max\+\_\+depth}{, }\item[{int}]{min\+\_\+samples\+\_\+split}{}\end{DoxyParamCaption})}



Constructor for the \doxylink{class_decision_tree}{Decision\+Tree} class. 

The default constructor is used here to initialize the root node to nullptr. \Hypertarget{class_decision_tree_a02eeb6db8794933b278d5e1399551058}\index{DecisionTree@{DecisionTree}!````~DecisionTree@{\texorpdfstring{$\sim$}{\string~}DecisionTree}}
\index{````~DecisionTree@{\texorpdfstring{$\sim$}{\string~}DecisionTree}!DecisionTree@{DecisionTree}}
\doxysubsubsection{\texorpdfstring{\texorpdfstring{$\sim$}{\string~}DecisionTree()}{\string~DecisionTree()}}
{\footnotesize\ttfamily \label{class_decision_tree_a02eeb6db8794933b278d5e1399551058} 
Decision\+Tree\+::\texorpdfstring{$\sim$}{\string~}\+Decision\+Tree (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [default]}}



Destructor for the \doxylink{class_decision_tree}{Decision\+Tree} class. 

The default destructor is used here to handle the destruction of the root node and its children. 

\doxysubsection{Member Function Documentation}
\Hypertarget{class_decision_tree_ad2548d5cda462085844cb8d977f9f8cd}\index{DecisionTree@{DecisionTree}!fit@{fit}}
\index{fit@{fit}!DecisionTree@{DecisionTree}}
\doxysubsubsection{\texorpdfstring{fit()}{fit()}}
{\footnotesize\ttfamily \label{class_decision_tree_ad2548d5cda462085844cb8d977f9f8cd} 
void Decision\+Tree\+::fit (\begin{DoxyParamCaption}\item[{std\+::shared\+\_\+ptr$<$ \mbox{\hyperlink{class_data_frame}{Data\+Frame}} $>$}]{df}{, }\item[{const std\+::string \&}]{label\+\_\+column}{}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [override]}, {\ttfamily [virtual]}}



The fit method trains the decision tree using the ID3 algorithm. 


\begin{DoxyParams}{Parameters}
{\em df} & unique\+\_\+ptr to the \doxylink{class_data_frame}{Data\+Frame} object containing the training data \\
\hline
{\em label\+\_\+column} & Name of the column in the \doxylink{class_data_frame}{Data\+Frame} that contains the class labels\\
\hline
\end{DoxyParams}
This is the entry point for training the decision tree. The function takes a unique\+\_\+ptr to a \doxylink{class_data_frame}{Data\+Frame} and the name of the column containing the class labels. The function then calls the fit\+\_\+helper() method to build the decision tree using the ID3 algorithm.

\begin{DoxySeeAlso}{See also}
fit\+\_\+helper(unique\+\_\+ptr$<$\+Data\+Frame$>$ df, string label\+\_\+column, int max\+\_\+depth, int min\+\_\+samples\+\_\+split) 

Classifier\+::fit(unique\+\_\+ptr$<$\+Data\+Frame$>$ df, string label\+\_\+column)
\end{DoxySeeAlso}

\begin{DoxyCode}{0}
\DoxyCodeLine{std::vector<std::vector<double>>\ data1\ =\ \{\{2.5,\ 1.5,\ 0\},\ \{1.0,\ 3.0,\ 1\},\ \{3.5,\ 2.0,\ 0\},\ \{4.0,\ 3.5,\ 1\},\ \{5.0,\ 2.5,\ 1\}\};}
\DoxyCodeLine{std::vector<std::string>\ columns1\ =\ \{\textcolor{stringliteral}{"{}A"{}},\ \textcolor{stringliteral}{"{}B"{}},\ \textcolor{stringliteral}{"{}C"{}}\};}
\DoxyCodeLine{unique\_ptr<DataFrame>\ df1\ =\ std::make\_unique<DataFrame>(data1,\ columns1);}
\DoxyCodeLine{\mbox{\hyperlink{class_decision_tree_a1ba47e4a3519b4eb63bb6e23e792b32d}{DecisionTree}}\ dt1(3,1);}
\DoxyCodeLine{dt1.fit(std::move(df1),\ \textcolor{stringliteral}{"{}C"{}});}

\end{DoxyCode}
 

Implements \mbox{\hyperlink{class_classifier}{Classifier}}.

\Hypertarget{class_decision_tree_a375a37a13ace5f6e303f7e180f73f0e8}\index{DecisionTree@{DecisionTree}!get\_height@{get\_height}}
\index{get\_height@{get\_height}!DecisionTree@{DecisionTree}}
\doxysubsubsection{\texorpdfstring{get\_height()}{get\_height()}}
{\footnotesize\ttfamily \label{class_decision_tree_a375a37a13ace5f6e303f7e180f73f0e8} 
int Decision\+Tree\+::get\+\_\+height (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption})}



Get the height of the decision tree. 

\begin{DoxyReturn}{Returns}
the height, as an integer, of the fitted decision tree.
\end{DoxyReturn}
This function returns the height of the decision tree starting from the root node. In the case that tree is empty or consists of a single leaf node (i.\+e. the root is a leaf node) the function returns 0. The function simply calls the \doxylink{class_decision_tree_a375a37a13ace5f6e303f7e180f73f0e8}{get\+\_\+height()} method of the root, which recursively calculates the height of its children.

\begin{DoxySeeAlso}{See also}
\doxylink{class_node_aa8ce774f99b4384d233dd8daa896b2f0}{Node\+::get\+\_\+height()} 
\end{DoxySeeAlso}
\Hypertarget{class_decision_tree_a5f555b5ecf4a639abae198d996e49a5a}\index{DecisionTree@{DecisionTree}!get\_num\_nodes@{get\_num\_nodes}}
\index{get\_num\_nodes@{get\_num\_nodes}!DecisionTree@{DecisionTree}}
\doxysubsubsection{\texorpdfstring{get\_num\_nodes()}{get\_num\_nodes()}}
{\footnotesize\ttfamily \label{class_decision_tree_a5f555b5ecf4a639abae198d996e49a5a} 
int Decision\+Tree\+::get\+\_\+num\+\_\+nodes (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption})}



Get the number of nodes in the decision tree. 

\begin{DoxyReturn}{Returns}
Number of nodes in the decision tree
\end{DoxyReturn}
This function returns the number of nodes in the decision tree. The function simply calls the \doxylink{class_decision_tree_a5f555b5ecf4a639abae198d996e49a5a}{get\+\_\+num\+\_\+nodes()} method of the root node, which recursively calculates the number of nodes in the tree.

\begin{DoxySeeAlso}{See also}
\doxylink{class_node_a79538468d2e025e22bbfd5089f364921}{Node\+::get\+\_\+num\+\_\+nodes()} 
\end{DoxySeeAlso}
\Hypertarget{class_decision_tree_a012ddf141c98805dee234feda82bfbb7}\index{DecisionTree@{DecisionTree}!predict@{predict}}
\index{predict@{predict}!DecisionTree@{DecisionTree}}
\doxysubsubsection{\texorpdfstring{predict()}{predict()}}
{\footnotesize\ttfamily \label{class_decision_tree_a012ddf141c98805dee234feda82bfbb7} 
double Decision\+Tree\+::predict (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ double $>$ \&}]{sample}{}\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [override]}, {\ttfamily [virtual]}}



Predict method. 


\begin{DoxyParams}{Parameters}
{\em sample} & Vector of feature values for a single sample \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
Predicted class label for the sample 
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em runtime\+\_\+error} & if the decision tree is not trained\\
\hline
\end{DoxyExceptions}
This function takes a vector of feature values for a single sample and returns the predicted. class label. The function traverses the decision tree starting from the root node and follows the decision rules at each node to determine the predicted class label for the sample. The actual recusion is implemented in the \doxylink{class_node}{Node} class, and this function simply calls the \doxylink{class_decision_tree_a012ddf141c98805dee234feda82bfbb7}{predict()} method of the root node.

\begin{DoxySeeAlso}{See also}
Node\+::predict(std\+::vector$<$double$>$ sample) 

Decision\+Node\+::predict(const std\+::vector$<$double$>$\& sample) const 

\doxylink{class_leaf_node_a0ae89708c0dc131c1c2741a8b01b70a9}{Leaf\+Node\+::predict(const vector$<$double$>$\& sample) const} 

Classifier\+::predict(std\+::vector$<$double$>$ sample)
\end{DoxySeeAlso}

\begin{DoxyCode}{0}
\DoxyCodeLine{std::vector<std::vector<double>>\ data1\ =\ \{\{2.5,\ 1.5,\ 0\},\ \{1.0,\ 3.0,\ 1\},\ \{3.5,\ 2.0,\ 0\},\ \{4.0,\ 3.5,\ 1\},\ \{5.0,\ 2.5,\ 1\}\};}
\DoxyCodeLine{std::vector<std::string>\ columns1\ =\ \{\textcolor{stringliteral}{"{}A"{}},\ \textcolor{stringliteral}{"{}B"{}},\ \textcolor{stringliteral}{"{}C"{}}\};}
\DoxyCodeLine{unique\_ptr<DataFrame>\ df1\ =\ std::make\_unique<DataFrame>(data1,\ columns1);}
\DoxyCodeLine{\mbox{\hyperlink{class_decision_tree_a1ba47e4a3519b4eb63bb6e23e792b32d}{DecisionTree}}\ dt1;}
\DoxyCodeLine{dt1.\mbox{\hyperlink{class_decision_tree_ad2548d5cda462085844cb8d977f9f8cd}{fit}}(std::move(df1),\ \textcolor{stringliteral}{"{}C"{}},\ 3,\ 1);}
\DoxyCodeLine{std::cout\ <<\ dt1.\mbox{\hyperlink{class_decision_tree_a012ddf141c98805dee234feda82bfbb7}{predict}}(\{2.5,\ 1.5\})\ <<\ std::endl;}

\end{DoxyCode}
 

Implements \mbox{\hyperlink{class_classifier}{Classifier}}.

\Hypertarget{class_decision_tree_a87a02c9842a2e727248535d86bcfb29e}\index{DecisionTree@{DecisionTree}!print@{print}}
\index{print@{print}!DecisionTree@{DecisionTree}}
\doxysubsubsection{\texorpdfstring{print()}{print()}}
{\footnotesize\ttfamily \label{class_decision_tree_a87a02c9842a2e727248535d86bcfb29e} 
string Decision\+Tree\+::print (\begin{DoxyParamCaption}\item[{vector$<$ string $>$}]{col\+\_\+names}{}\end{DoxyParamCaption})}



Print method for the decision tree. 


\begin{DoxyParams}{Parameters}
{\em col\+\_\+names} & Vector of column names from the \doxylink{class_data_frame}{Data\+Frame} that was used to train the decision tree \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
String representation of the decision tree
\end{DoxyReturn}
This function returns a string representation of the decision tree. The function calls the print\+\_\+helper() method to traverse the tree starting from the root node and build the string representation of the tree.

\begin{DoxySeeAlso}{See also}
print\+\_\+helper(const Node\texorpdfstring{$\ast$}{*} node, const vector$<$string$>$\& col\+\_\+names, const string\& prefix, bool is\+Left, std\+::ostringstream\& oss) 

\doxylink{class_node_abd3b4b561203553104c753fb944b2dad}{Node\+::print()}
\end{DoxySeeAlso}

\begin{DoxyCode}{0}
\DoxyCodeLine{std::vector<std::vector<double>>\ data1\ =\ \{\{2.5,\ 1.5,\ 0\},\ \{1.0,\ 3.0,\ 1\},\ \{3.5,\ 2.0,\ 0\},\ \{4.0,\ 3.5,\ 1\},\ \{5.0,\ 2.5,\ 1\}\};}
\DoxyCodeLine{std::vector<std::string>\ columns1\ =\ \{\textcolor{stringliteral}{"{}A"{}},\ \textcolor{stringliteral}{"{}B"{}},\ \textcolor{stringliteral}{"{}C"{}}\};}
\DoxyCodeLine{unique\_ptr<DataFrame>\ df1\ =\ std::make\_unique<DataFrame>(data1,\ columns1);}
\DoxyCodeLine{\mbox{\hyperlink{class_decision_tree_a1ba47e4a3519b4eb63bb6e23e792b32d}{DecisionTree}}\ dt1;}
\DoxyCodeLine{dt1.\mbox{\hyperlink{class_decision_tree_ad2548d5cda462085844cb8d977f9f8cd}{fit}}(std::move(df1),\ \textcolor{stringliteral}{"{}C"{}},\ 3,\ 1);}
\DoxyCodeLine{std::cout\ <<\ dt1.\mbox{\hyperlink{class_decision_tree_a87a02c9842a2e727248535d86bcfb29e}{print}}(columns1)\ <<\ std::endl;}

\end{DoxyCode}
 

The documentation for this class was generated from the following files\+:\begin{DoxyCompactItemize}
\item 
src/Decision\+Tree.\+h\item 
src/Decision\+Tree.\+cpp\end{DoxyCompactItemize}
